# Job Scraper & Evaluation

For Seminar Algorithmic Auditing, FS24.

## Setup

### Python

#### Using Conda (recommended)

```sh
# at project root
conda create -p ./envs python=3.12.*
conda activate ./envs
pip install -r requirements.txt
```

Depending on your system and configuration, the above commands might not work (e.g. using conda 24.1.0 on a Mac required other commands).
Try the following instead:

```sh
conda create -p ./envs python=3.12.\*
conda activate ./envs
pip install -r requirements.txt
```


### VSCode

Copy `settings.json.default` to `settings.json`.

```sh
# at project root
cp .vscode/settings.json.default .vscode/settings.json
```

Make sure you're using the correct interpreter with VSCode.

<kbd>CTRL</kbd> + <kbd>P</kbd> > "Python: Select Interpreter" > ".envs/bin/python".

## Run Scraper

It is recommended to install microconda (works better with VSCode) or micromamba.

### Using Conda (recommended)

```sh
conda activate ./envs
cd scraper/ # important
python main.py
```

## Run Evaluation

### Requirements

Before running the evaluations, the following files have to be present in the `input` folder:
- `keywords.yml` &rarr; yaml file containing all keywords per job group
- csv files with results from scraping (one file per job group)

### Using Conda (recommended)

```sh
conda activate ./envs
cd evaluation/ # important
python [job_numbers.py | stats_anova.py | rank_comparison.py]
```

### Known Issues

If you encounter the following error when running the evaluation:
`ValueError: --plotlyjs argument is not a valid URL or file path`
This is due to a flaw in the Kaleido library.  Remove all spaces and accents in the project path
(e.g. use `.../Universitaet_Zuerich/...` instead of `.../Universität Zürich/...`)


### Available Evalutations

#### 1) Stacked Bar Charts (visual)
`python job_numbers.py`

Creates a stacked bar chart for each job group, indicating the distribution of job offers within all possible
keyword combinations.

#### 2) Statistical Data (numerical)
`python stats_anova.py`

Shows overall statistical data for the scraping results:
- One-way ANOVA
- Repeated measures ANOVA
- Pairwise comparison

The script determines whether or not there is a  statistically significant difference between the means of the
categories.

`stats_anova.py` requires the `anova.csv` file which is generated by `job_distributions.py`.
If the file is not present at runtime, `stats_anova.py` automatically triggers `job_distributions.py`
prior to calculating the statistics.

#### 3) Rank Comparisons (visual)
`python rank_comparison.py`

Pairwise comparison of keywords:

*3a) Kendall’s Tau*

Measures ordinal association between rankings by comparing pairwise concordance and discordance between orders.

*3b) Ranking Correlation Scatterplots*

Visual display of correlations between (relative) rankings.


